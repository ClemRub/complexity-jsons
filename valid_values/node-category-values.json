{
  "mdpType": [
    [
      "MDP",
      "PIMDP",
      "Markov Decision Process",
      "Perfect Information MDP",
      "Perfect Information Markov Decision Process"
    ],
    [
      "POMDP",
      "+",
      "Observationless MDP",
      "UOMDP",
      "Unobservable MDP"
    ],
    [
      "Observationless MDP",
      "UOMDP",
      "Unobservable MDP"
    ],
    [
      "RMDP",
      "rMDP",
      "Robust MDP"
    ],
    [
      "Miscellaneous",
      "Arbitrary",
      "Any",
      "All"
    ],
    [
      "MEMDP",
      "Multiple Environment MDP",
      "Multi-Environment MDP"
    ],
    [
      "pMDP",
      "PMDP",
      "Parametric MDP"
    ],
    [
      "Time-delayed MDP"
    ],
    [
      "MOMDP",
      "Multiple Objective MDP"
    ],
    [
      "OBMDP"
    ],
    [
      "pMC",
      "PMC",
      "Parametric MC",
      "Parametric Markov Chain"
    ]
  ],
  "problemType": [
    [
      "Reward Maximisation",
      "Reward Maximization",
      "Cost Minimisation",
      "Cost Minimization"
    ],
    [
      "Target Reward",
      "Exact Reward"
    ],
    [
      "Reachability"
    ],
    [
      "Safety"
    ],
    [
      "Büchi",
      "Buchi"
    ],
    [
      "coBuchi",
      "coBüchi",
      "CoBuchi",
      "CoBüchi"
    ],
    [
      "Parity"
    ],
    [
      "Muller"
    ],
    [
      "Rabin"
    ],
    [
      "Other"
    ]
  ],
  "problemApproach": [
    [
      "Policy Existence",
      "Existence"
    ],
    [
      "Policy Evaluation",
      "Evaluation"
    ],
    [
      "Policy Computation",
      "Computation",
      "Unspecified",
      "Unspecified presuming computation as default",
      ""
    ],
    [
      "Policy Improvement",
      "Improvement"
    ]
  ],
  "complexityClass": [
    [
      "NL"
    ],
    [
      "PL"
    ],
    [
      "NC"
    ],
    [
      "P"
    ],
    [
      "NP"
    ],
    [
      "PP"
    ],
    [
      "ETR",
      "Existential theory of the reals"
    ],
    [
      "PSPACE"
    ],
    [
      "EXP",
      "EXPTIME"
    ],
    [
      "NEXP",
      "NEXPTIME"
    ],
    [
      "EXPSPACE"
    ],
    [
      "Decidable not otherwise specified",
      "Decidable"
    ],
    [
      "Undecidable"
    ],
    [
      "Possibly Open",
      "Possibly Open Question",
      "Open?"
    ],
    [
      "Open Question",
      "Open"
    ],
    [
      "NPPP",
      "NP^PP"
    ]
  ],
  "complexitySuffix": [
    [
      "hard"
    ],
    [
      "complete"
    ]
  ],
  "horizonType": [
    [
      "Finite Horizon",
      "Finite"
    ],
    [
      "Infinite",
      "Infinite Horizon Average",
      "Infinite Average",
      "Infinite Horizon Discounted",
      "Infinite Discounted"
    ],
    [
      "Infinite Horizon Average",
      "Infinite Average"
    ],
    [
      "Infinite Horizon Discounted",
      "Infinite Discounted"
    ],
    [
      "Not Clearly Stated",
      ""
    ],
    [
      "Other"
    ]
  ],
  "determinism": [
    [
      "Deterministic",
      "Pure"
    ],
    [
      "Randomized"
    ],
    [
      "Nondeterministic"
    ]
  ],
  "dependenceType": [
    [
      "Stationary"
    ],
    [
      "Nonstationary",
      "Nonstationary General",
      "Time-dependent",
      "Time",
      "History-dependent",
      "History"
    ],
    [
      "Time-dependent",
      "Time"
    ],
    [
      "History-dependent",
      "History"
    ]
  ],
  "policyMemory": [
    [
      "Finite"
    ],
    [
      "Infinite",
      "infinite"
    ],
    [
      "Memoryless",
      "None"
    ]
  ],
  "analysisType": [
    [
      "Quantitative"
    ],
    [
      "Qualitative",
      "Almost-sure",
      "Positive",
      "Limit-sure"
    ],
    [
      "Almost-sure"
    ],
    [
      "Positive",
      "Possible"
    ],
    [
      "Limit-sure"
    ]
  ],
  "rewardConstraint": [
    [
      "None"
    ],
    [
      "Nonnegative Only"
    ]
  ],
  "ambiguitySetRectangularity": [
    [
      "Nonrectangular"
    ],
    [
      "s-rectangular"
    ],
    [
      "(s,a)-rectangular",
      "s,a-rectangular"
    ]
  ],
  "ambiguitySetConvexness": [
    [
      "Nonconvex"
    ],
    [
      "Convex"
    ]
  ],
  "mdpRepresentation": [
    [
      "Flat"
    ],
    [
      "Succinct"
    ],
    [
      "Compressed"
    ]
  ],
  "special": [
    [
      "COMMENT:",
      "Special categories are ment to be exclusive, not inclusive.",
      "As to say, these will not be included unless you enable either",
      "all special or that specific one, itll not display.",
      "(for now, its enabled by default to show all)"
    ],
    [
      "2-MEMDP"
    ],
    [
      "Time-sensitive MEMDP"
    ],
    [
      "MO-OBMDP"
    ],
    [
      "Atypical reward shape"
    ],
    [
      "pMDP-Fixed number of parameters",
      "Fixed number of parameters"
    ]
  ],
  "proofType": [
    [
      "Reduction"
    ],
    [
      "Guess and Verify"
    ],
    [
      "Structure"
    ],
    [
      "Parallelization"
    ],
    [
      "Consequence of other proof"
    ],
    [
      "Follows from different paper"
    ],
    [
      "Other"
    ],
    [
      "Unclear"
    ]
  ]
}